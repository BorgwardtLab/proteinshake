{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe480e2",
   "metadata": {
    "id": "cbe480e2"
   },
   "source": [
    "# Supervised enzyme commission prediction with GNNs\n",
    "\n",
    "This tutorial demonstrates how to train a GNN with ProteinShake and [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/) for enzyme commission prediction. You can adapt the code for any downstream tasks provided by ProteinShake.\n",
    "\n",
    "We will use a simple GNN model, namely [GCN](https://arxiv.org/abs/1609.02907), and evaluate its performance for enzyme commission prediction. The model can be trained with either CPU or GPU, but GPU is recommended for faster computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c0941",
   "metadata": {
    "id": "c51c0941"
   },
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9105a3b5",
   "metadata": {
    "id": "9105a3b5"
   },
   "source": [
    "If you are using colab, then uncomment and run the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8edf3f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8edf3f8",
    "outputId": "cd20d77a-f908-413d-ed16-75f9fbfd468f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/BorgwardtLab/proteinshake.git\n",
      "  Cloning https://github.com/BorgwardtLab/proteinshake.git to /tmp/pip-req-build-g2fvw02x\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/BorgwardtLab/proteinshake.git /tmp/pip-req-build-g2fvw02x\n",
      "  Resolved https://github.com/BorgwardtLab/proteinshake.git to commit dc8f8367c8b39c5261f0cfdeb2dc6b4d570ecb3d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (1.21.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (1.7.3)\n",
      "Requirement already satisfied: biopandas in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (0.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (1.0.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (4.64.1)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (2.25.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (1.2.0)\n",
      "Requirement already satisfied: rdkit in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (2022.9.4)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (0.8.10)\n",
      "Requirement already satisfied: fastavro in /usr/local/lib/python3.8/dist-packages (from proteinshake==0.2.1) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from biopandas->proteinshake==0.2.1) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from biopandas->proteinshake==0.2.1) (57.4.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit->proteinshake==0.2.1) (7.1.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->proteinshake==0.2.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->proteinshake==0.2.1) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->proteinshake==0.2.1) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->proteinshake==0.2.1) (2.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->proteinshake==0.2.1) (3.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->biopandas->proteinshake==0.2.1) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->biopandas->proteinshake==0.2.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->biopandas->proteinshake==0.2.1) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
      "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.8/dist-packages (0.1.0+pt113cu116)\n",
      "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.8/dist-packages (2.1.0+pt113cu116)\n",
      "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.8/dist-packages (0.6.16+pt113cu116)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install git+https://github.com/BorgwardtLab/proteinshake.git\n",
    "# !pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
    "# !pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04c0f41",
   "metadata": {
    "id": "b04c0f41"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from proteinshake import tasks as ps_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cbe99",
   "metadata": {
    "id": "485cbe99"
   },
   "source": [
    "## Load the task and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dcd8784",
   "metadata": {
    "id": "5dcd8784"
   },
   "outputs": [],
   "source": [
    "datapath = './data/ec'\n",
    "task = ps_tasks.EnzymeCommissionTask(root=datapath)\n",
    "dset = task.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02a0ad",
   "metadata": {
    "id": "2e02a0ad"
   },
   "source": [
    "We convert the protein 3D structures to $\\epsilon$-graphs ($\\epsilon=8$ here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0514d14",
   "metadata": {
    "id": "f0514d14"
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    data, protein_dict = data\n",
    "    data.y = task.target(protein_dict)\n",
    "    return data\n",
    "    \n",
    "dset = dset.to_graph(eps=8.0).pyg(\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728675a",
   "metadata": {
    "id": "1728675a"
   },
   "source": [
    "## Load train/val/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6755d",
   "metadata": {
    "id": "3ef6755d"
   },
   "source": [
    "We can now create data loaders for train/val/test sets provided by ProteinShake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfd6485",
   "metadata": {
    "id": "8bfd6485"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71341596",
   "metadata": {
    "id": "71341596"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(Subset(dset, task.train_index), batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(Subset(dset, task.val_index), batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(Subset(dset, task.test_index), batch_size=batch_size,\n",
    "                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d72ff",
   "metadata": {
    "id": "1e9d72ff"
   },
   "source": [
    "## Build GNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434194bc",
   "metadata": {
    "id": "434194bc"
   },
   "source": [
    "Here, we build a simple GNN model for this task, namely [GCN](https://arxiv.org/abs/1609.02907)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1048662e",
   "metadata": {
    "id": "1048662e"
   },
   "outputs": [],
   "source": [
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e08ecc",
   "metadata": {
    "id": "a6e08ecc"
   },
   "outputs": [],
   "source": [
    "class GCNConv(gnn.MessagePassing):\n",
    "    def __init__(self, embed_dim=256, use_edge_attr=False):\n",
    "        super().__init__(aggr='add')\n",
    "        self.use_edge_attr = use_edge_attr\n",
    "\n",
    "        self.linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.root_emb = nn.Embedding(1, embed_dim)\n",
    "        self.edge_encoder = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x = self.linear(x)\n",
    "        if self.use_edge_attr and edge_attr is not None:\n",
    "            edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        row, col = edge_index\n",
    "\n",
    "        deg = utils.degree(row, x.size(0), dtype = x.dtype) + 1\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return self.propagate(\n",
    "            edge_index, x=x, edge_attr = edge_attr, norm=norm) + F.relu(\n",
    "            x + self.root_emb.weight) * 1./deg.view(-1,1)\n",
    "\n",
    "    def message(self, x_j, edge_attr, norm):\n",
    "        return norm.view(-1, 1) * F.relu(x_j + edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a98aa1df",
   "metadata": {
    "id": "a98aa1df"
   },
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, embed_dim=256, num_layers=3, dropout=0.0,\n",
    "                 use_edge_attr=False):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.x_embedding = nn.Embedding(20, embed_dim)\n",
    "\n",
    "        gnn_model = GCNConv\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.gnns.append(gnn_model(embed_dim, use_edge_attr=use_edge_attr))\n",
    "\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.batch_norms.append(nn.BatchNorm1d(embed_dim))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        output = self.x_embedding(x)\n",
    "\n",
    "        for layer in range(self.num_layers):\n",
    "            output = self.gnns[layer](output, edge_index, edge_attr)\n",
    "            output = self.batch_norms[layer](output)\n",
    "\n",
    "            if layer == self.num_layers - 1:\n",
    "                output = F.dropout(output, self.dropout, training=self.training)\n",
    "            else:\n",
    "                output = F.dropout(F.relu(output), self.dropout, training=self.training)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81191365",
   "metadata": {
    "id": "81191365"
   },
   "outputs": [],
   "source": [
    "class GNN_graphpred(nn.Module):\n",
    "    def __init__(self, num_class, embed_dim=64, num_layers=3, dropout=0.0,\n",
    "                 use_edge_attr=False, global_pool='mean'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = GNN(embed_dim, num_layers, dropout, use_edge_attr)\n",
    "\n",
    "        self.global_pool = global_pool\n",
    "        if global_pool == 'mean':\n",
    "            self.pooling = gnn.global_mean_pool\n",
    "        elif global_pool == 'add':\n",
    "            self.pooling = gnn.global_add_pool\n",
    "        elif global_pool == 'max':\n",
    "            self.pooling = gnn.global_max_pool\n",
    "        elif global_pool is None:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.classifier = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, data, other_data = None):\n",
    "        bsz = len(data.ptr) - 1\n",
    "        output = self.encoder(data)\n",
    "        if self.pooling is not None:\n",
    "            output = self.pooling(output, data.batch)\n",
    "        return self.classifier(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2bb8fd",
   "metadata": {
    "id": "bb2bb8fd"
   },
   "source": [
    "We build a GCN model with 5 layers and 64 hidden dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d98a9ec",
   "metadata": {
    "id": "4d98a9ec"
   },
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "num_layers = 5\n",
    "\n",
    "model = GNN_graphpred(\n",
    "    task.num_classes,\n",
    "    embed_dim,\n",
    "    num_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c441b7",
   "metadata": {
    "id": "03c441b7"
   },
   "source": [
    "## Build an optimizer and define the train and test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fcb46bd",
   "metadata": {
    "id": "1fcb46bd"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "DTH1p_8rGsia",
   "metadata": {
    "id": "DTH1p_8rGsia"
   },
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device(torch.cuda.current_device()) \\\n",
    "        if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c86de08",
   "metadata": {
    "id": "3c86de08"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        size = len(batch.y)\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(batch)\n",
    "\n",
    "        loss = criterion(y_hat, batch.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * size\n",
    "\n",
    "    n_sample = len(train_loader.dataset)\n",
    "    epoch_loss = running_loss / n_sample\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QFxR97Z1MtCY",
   "metadata": {
    "id": "QFxR97Z1MtCY"
   },
   "source": [
    "ProteinShake provides an evaluation function for each task `task.evaluate(y_true, y_pred)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccaf9787",
   "metadata": {
    "id": "ccaf9787"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        y_hat = model(batch)\n",
    "\n",
    "        y_true.append(batch.y.cpu())\n",
    "        y_pred.append(y_hat.cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.vstack(y_pred).numpy()\n",
    "    y_pred = y_pred.argmax(-1)\n",
    "    scores = task.evaluate(y_true, y_pred)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4171e",
   "metadata": {
    "id": "63f4171e"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "XcIPkP5ZHIRO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcIPkP5ZHIRO",
    "outputId": "b0fd860e-1d81-4105-e140-b7097702d1de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN_graphpred(\n",
       "  (encoder): GNN(\n",
       "    (x_embedding): Embedding(20, 64)\n",
       "    (gnns): ModuleList(\n",
       "      (0): GCNConv()\n",
       "      (1): GCNConv()\n",
       "      (2): GCNConv()\n",
       "      (3): GCNConv()\n",
       "      (4): GCNConv()\n",
       "    )\n",
       "    (batch_norms): ModuleList(\n",
       "      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=64, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5b2f3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd5b2f3f",
    "outputId": "427861ed-c582-46ea-d03e-5273c3506c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:02<00:00, 15.13s/it, train_loss=0.53, val_acc=0.655]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20 # we train only 20 epochs here, but more epochs may result in better performance.\n",
    "\n",
    "best_val_score = 0.0\n",
    "pbar = tqdm(range(epochs))\n",
    "for epoch in pbar:\n",
    "    train_loss = train_epoch(model)\n",
    "    val_scores = eval_epoch(model, val_loader)\n",
    "    val_score = val_scores['accuracy']\n",
    "    postfix = {'train_loss': train_loss, 'val_acc': val_score}\n",
    "    pbar.set_postfix(postfix)\n",
    "    \n",
    "    if val_score > best_val_score:\n",
    "        best_val_score = val_score\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VCCA1ecgJwm2",
   "metadata": {
    "id": "VCCA1ecgJwm2"
   },
   "source": [
    "## Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "uFijiPBoJ2cB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFijiPBoJ2cB",
    "outputId": "c5d93d42-3bc2-4b14-f013-d5915f02c2ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5333515066547034, 'recall': 0.4799021029676011, 'accuracy': 0.6675514266755143}\n"
     ]
    }
   ],
   "source": [
    "test_scores = eval_epoch(model, test_loader)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2n4LfXTZK0vX",
   "metadata": {
    "id": "2n4LfXTZK0vX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a36319596c8b85aa3a33b7572e0064796912a6e6e60d26f47e4d35330b02900"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
